{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna を TensorFlow で試してみる\n",
    "- Reference\n",
    "  - https://github.com/optuna/optuna/blob/master/examples/tensorflow_eager_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pkg_resources.parse_version(tf.__version__) < pkg_resources.parse_version(\"2.0.0\"):\n",
    "    raise RuntimeError(\"tensorflow>=2.0.0 is required for this example.\")\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 0us/step\n",
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-10, 1e-3)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = int(trial.suggest_loguniform(\"n_units_l{}\".format(i), 4, 128))\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                num_hidden,\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(CLASSES, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial):\n",
    "    kwargs = {}\n",
    "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
    "    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
    "\n",
    "    if optimizer_selected == \"RMSprop\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_loguniform(\"rmsprop_learning_rate\", 1e-5, 1e-1)\n",
    "        kwargs[\"decay\"] = trial.suggest_uniform(\"rmsprop_decay\", 0.85, 0.99)\n",
    "        kwargs[\"momentum\"] = trial.suggest_loguniform(\"rmsprop_momentum\", 1e-5, 1e-1)\n",
    "\n",
    "    elif optimizer_selected == \"Adam\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_loguniform(\"adam_learning_rate\", 1e-5, 1e-1)\n",
    "\n",
    "    elif optimizer_selected == \"SGD\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_loguniform(\"sgd_opt_learning_rate\", 1e-5, 1e-1)\n",
    "        kwargs[\"momentum\"] = trial.suggest_loguniform(\"sgd_opt_momentum\", 1e-5, 1e-1)\n",
    "\n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(model, optimizer, dataset, mode=\"eval\"):\n",
    "    accuracy = tf.metrics.Accuracy(\"accuracy\", dtype=tf.float32)\n",
    "\n",
    "    for batch, (images, labels) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(images, training=(mode == \"train\"))\n",
    "            loss_value = tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "            )\n",
    "\n",
    "            if mode == \"eval\":\n",
    "                accuracy(\n",
    "                    tf.argmax(logits, axis=1, output_type=tf.int64), tf.cast(labels, tf.int64)\n",
    "                )\n",
    "            else:\n",
    "                grads = tape.gradient(loss_value, model.variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.variables))\n",
    "\n",
    "    if mode == \"eval\":\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    (x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_valid = x_valid.astype(\"float32\") / 255\n",
    "\n",
    "    y_train = y_train.astype(\"int32\")\n",
    "    y_valid = y_valid.astype(\"int32\")\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.shuffle(60000).batch(BATCHSIZE).take(N_TRAIN_EXAMPLES)\n",
    "\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "    valid_ds = valid_ds.shuffle(10000).batch(BATCHSIZE).take(N_VALID_EXAMPLES)\n",
    "\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train_ds, valid_ds = get_mnist()\n",
    "\n",
    "    model = create_model(trial)\n",
    "    optimizer = create_optimizer(trial)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        for _ in range(EPOCHS):\n",
    "            learn(model, optimizer, train_ds, \"train\")\n",
    "\n",
    "        accuracy = learn(model, optimizer, valid_ds, \"eval\")\n",
    "\n",
    "    return accuracy.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-21 20:13:35,209] Finished trial#0 with value: 0.44909998774528503 with parameters: {'n_layers': 2, 'weight_decay': 1.0306354678511479e-09, 'n_units_l0': 18.701334875543605, 'n_units_l1': 21.721065593915235, 'optimizer': 'Adam', 'adam_learning_rate': 3.8071199615243025e-05}. Best is trial#0 with value: 0.44909998774528503.\n",
      "[I 2020-06-21 20:13:38,662] Finished trial#1 with value: 0.10970000177621841 with parameters: {'n_layers': 3, 'weight_decay': 7.382097783465894e-06, 'n_units_l0': 36.73214531831566, 'n_units_l1': 7.8062325271984605, 'n_units_l2': 56.52211476840823, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 7.035948426789005e-05, 'sgd_opt_momentum': 0.00018728118078059335}. Best is trial#0 with value: 0.44909998774528503.\n",
      "[I 2020-06-21 20:13:41,964] Finished trial#2 with value: 0.08990000188350677 with parameters: {'n_layers': 3, 'weight_decay': 3.5380798065151636e-08, 'n_units_l0': 13.574619272024263, 'n_units_l1': 8.967318830880219, 'n_units_l2': 35.33196774288219, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 1.1503116585515679e-05, 'sgd_opt_momentum': 6.804418248966186e-05}. Best is trial#0 with value: 0.44909998774528503.\n",
      "[I 2020-06-21 20:13:44,927] Finished trial#3 with value: 0.18400000035762787 with parameters: {'n_layers': 1, 'weight_decay': 4.3759043921990776e-10, 'n_units_l0': 6.359793653221357, 'optimizer': 'Adam', 'adam_learning_rate': 1.17038829920315e-05}. Best is trial#0 with value: 0.44909998774528503.\n",
      "[I 2020-06-21 20:13:47,811] Finished trial#4 with value: 0.8510000109672546 with parameters: {'n_layers': 1, 'weight_decay': 1.328531366598761e-09, 'n_units_l0': 20.903963784733122, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.016992769547961764, 'rmsprop_decay': 0.9163941819252213, 'rmsprop_momentum': 0.000596303692848477}. Best is trial#4 with value: 0.8510000109672546.\n",
      "[I 2020-06-21 20:13:51,237] Finished trial#5 with value: 0.19339999556541443 with parameters: {'n_layers': 2, 'weight_decay': 1.775618761602312e-09, 'n_units_l0': 71.02705422446006, 'n_units_l1': 81.5859956867902, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0003563871558068433, 'sgd_opt_momentum': 0.0006663164271229127}. Best is trial#4 with value: 0.8510000109672546.\n",
      "[I 2020-06-21 20:13:53,849] Finished trial#6 with value: 0.09510000050067902 with parameters: {'n_layers': 1, 'weight_decay': 0.0009481228304469742, 'n_units_l0': 6.077799413518948, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.00023734934793867723, 'sgd_opt_momentum': 0.0560809739950355}. Best is trial#4 with value: 0.8510000109672546.\n",
      "[I 2020-06-21 20:13:57,558] Finished trial#7 with value: 0.23389999568462372 with parameters: {'n_layers': 3, 'weight_decay': 1.1591165487318399e-09, 'n_units_l0': 16.535849538825282, 'n_units_l1': 4.539913283604303, 'n_units_l2': 7.459900625678398, 'optimizer': 'Adam', 'adam_learning_rate': 8.884788783096886e-05}. Best is trial#4 with value: 0.8510000109672546.\n",
      "[I 2020-06-21 20:14:00,620] Finished trial#8 with value: 0.8959000110626221 with parameters: {'n_layers': 2, 'weight_decay': 0.0002787496127857389, 'n_units_l0': 19.48318015171697, 'n_units_l1': 24.414156242286204, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.043968092971524486, 'sgd_opt_momentum': 0.0006164244658745656}. Best is trial#8 with value: 0.8959000110626221.\n",
      "[I 2020-06-21 20:14:03,727] Finished trial#9 with value: 0.9085999727249146 with parameters: {'n_layers': 2, 'weight_decay': 7.977875642988996e-08, 'n_units_l0': 33.20296716895364, 'n_units_l1': 8.18795475869141, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09743711002872078, 'sgd_opt_momentum': 7.941912394870229e-05}. Best is trial#9 with value: 0.9085999727249146.\n",
      "[I 2020-06-21 20:14:07,413] Finished trial#10 with value: 0.11969999969005585 with parameters: {'n_layers': 2, 'weight_decay': 1.1304191162849433e-06, 'n_units_l0': 83.76778884495828, 'n_units_l1': 18.289264514029387, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 3.38125765678341e-05, 'rmsprop_decay': 0.9859769936804232, 'rmsprop_momentum': 0.08261525913378827}. Best is trial#9 with value: 0.9085999727249146.\n",
      "[I 2020-06-21 20:14:10,572] Finished trial#11 with value: 0.9110000133514404 with parameters: {'n_layers': 2, 'weight_decay': 0.00030415917277580855, 'n_units_l0': 37.88582244358547, 'n_units_l1': 69.64864246804716, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.06492361453809503, 'sgd_opt_momentum': 1.0452532190849313e-05}. Best is trial#11 with value: 0.9110000133514404.\n",
      "[I 2020-06-21 20:14:13,685] Finished trial#12 with value: 0.9211999773979187 with parameters: {'n_layers': 2, 'weight_decay': 6.31133734459572e-08, 'n_units_l0': 40.69982964409763, 'n_units_l1': 72.42731745597784, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09202340122938332, 'sgd_opt_momentum': 1.3862233175784708e-05}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:16,867] Finished trial#13 with value: 0.7736999988555908 with parameters: {'n_layers': 2, 'weight_decay': 2.3143092279299513e-05, 'n_units_l0': 49.36926984769447, 'n_units_l1': 99.20878383703155, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.008510790934268023, 'sgd_opt_momentum': 1.009617670494938e-05}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:20,458] Finished trial#14 with value: 0.1941000074148178 with parameters: {'n_layers': 3, 'weight_decay': 1.394728800099244e-08, 'n_units_l0': 50.470095076157115, 'n_units_l1': 61.03025387744694, 'n_units_l2': 4.547255903253316, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.00667719047620554, 'sgd_opt_momentum': 1.052467891376224e-05}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:23,860] Finished trial#15 with value: 0.12380000203847885 with parameters: {'n_layers': 1, 'weight_decay': 6.299616003748424e-07, 'n_units_l0': 124.05131445640124, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.1913969020158312e-05, 'rmsprop_decay': 0.8505644396789542, 'rmsprop_momentum': 1.0297164301104804e-05}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:26,964] Finished trial#16 with value: 0.9106000065803528 with parameters: {'n_layers': 2, 'weight_decay': 2.3186993123551184e-05, 'n_units_l0': 29.642734518570652, 'n_units_l1': 46.423500230120645, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09801381882922292, 'sgd_opt_momentum': 0.047584315321254206}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:30,053] Finished trial#17 with value: 0.7335000038146973 with parameters: {'n_layers': 2, 'weight_decay': 1.9656420256770936e-07, 'n_units_l0': 10.147599364907087, 'n_units_l1': 125.02336801194849, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.014599759451814867, 'sgd_opt_momentum': 0.00743896855140444}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:33,047] Finished trial#18 with value: 0.5264999866485596 with parameters: {'n_layers': 1, 'weight_decay': 1.0226078286114513e-10, 'n_units_l0': 88.61951641567015, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0013909246292461068, 'sgd_opt_momentum': 1.6987114683541847e-05}. Best is trial#12 with value: 0.9211999773979187.\n",
      "[I 2020-06-21 20:14:36,670] Finished trial#19 with value: 0.8888000249862671 with parameters: {'n_layers': 3, 'weight_decay': 1.3302123755784383e-08, 'n_units_l0': 53.391394457700144, 'n_units_l1': 39.05073916628683, 'n_units_l2': 127.04448261599308, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.03233337202715354, 'sgd_opt_momentum': 3.2892792283723284e-05}. Best is trial#12 with value: 0.9211999773979187.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  20\n",
      "Best trial:\n",
      "  Value:  0.9211999773979187\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    weight_decay: 6.31133734459572e-08\n",
      "    n_units_l0: 40.69982964409763\n",
      "    n_units_l1: 72.42731745597784\n",
      "    optimizer: SGD\n",
      "    sgd_opt_learning_rate: 0.09202340122938332\n",
      "    sgd_opt_momentum: 1.3862233175784708e-05\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    #study.optimize(objective, n_trials=100)\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
