{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reference\n",
    "  - https://blog.shikoan.com/resnet-multiple-framework/\n",
    "  - https://github.com/koshian2/ResNet-MultipleFramework/blob/master/resnet_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Add, Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 経過時間用のコールバック\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, n, framework, channels_first=False, initial_lr=0.01, nb_epochs=100):\n",
    "        self.n = n\n",
    "        self.framework = framework\n",
    "\n",
    "        # 論文通りの初期学習率=0.1だと発散するので0.01にする\n",
    "        self.initial_lr = initial_lr\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.weight_decay = 0.0005\n",
    "\n",
    "        # MX-Netではchannels_firstなのでその対応をする\n",
    "        self.channels_first = channels_first\n",
    "        self.data_format = \"channels_first\" if channels_first else \"channels_last\"\n",
    "        self.bn_axis = 1 if channels_first else -1\n",
    "\n",
    "        # Make model\n",
    "        self.model = self.make_model()\n",
    "\n",
    "    # オリジナルの論文に従って、サブサンプリングにPoolingではなくstride=2のConvを使う\n",
    "    def subsumpling(self, output_channels, input_tensor):\n",
    "        return Conv2D(output_channels, kernel_size=1, strides=(2,2), data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input_tensor)\n",
    "\n",
    "    # BN->ReLU->Conv->BN->ReLU->Conv をショートカットさせる(Kaimingらの研究による)\n",
    "    # https://www.slideshare.net/KotaNagasato/resnet-82940994\n",
    "    def block(self, channles, input_tensor):\n",
    "        # ショートカット元\n",
    "        shortcut = input_tensor\n",
    "\n",
    "        # メイン側\n",
    "        x = BatchNormalization(axis=self.bn_axis)(input_tensor)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        x = BatchNormalization(axis=self.bn_axis)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "\n",
    "        # 結合\n",
    "        return Add()([x, shortcut])\n",
    "\n",
    "    def make_model(self):\n",
    "        input = Input(shape=(3, 32, 32)) if self.channels_first else Input(shape=(32, 32, 3))\n",
    "\n",
    "        # 3->16にチャンネル数を増やす\n",
    "        x = Conv2D(16, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input)\n",
    "\n",
    "        # 32x32x16のブロックをn回\n",
    "        for i in range(self.n):\n",
    "            x = self.block(16, x)\n",
    "\n",
    "        # 16x16x32\n",
    "        x = self.subsumpling(32, x)\n",
    "\n",
    "        for i in range(self.n):\n",
    "            x = self.block(32, x)\n",
    "\n",
    "        # 8x8x64\n",
    "        x = self.subsumpling(64, x)\n",
    "\n",
    "        for i in range(self.n):\n",
    "            x = self.block(64, x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = GlobalAveragePooling2D(data_format=self.data_format)(x)\n",
    "        x = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "        # model\n",
    "        model = Model(input, x)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def lr_schduler(self, epoch):\n",
    "        x = self.initial_lr\n",
    "        if epoch >= self.nb_epochs * 0.5: x /= 10.0\n",
    "        if epoch >= self.nb_epochs * 0.75: x /= 10.0\n",
    "        return x\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        # コンパイル\n",
    "        self.model.compile(optimizer=SGD(lr=self.initial_lr, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "        # Data Augmentation\n",
    "        traingen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=4./32,\n",
    "            height_shift_range=4./32,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "        valgen = ImageDataGenerator(\n",
    "            rescale=1./255)\n",
    "\n",
    "        # Callback\n",
    "        time_cb = TimeHistory()\n",
    "        lr_cb = LearningRateScheduler(self.lr_schduler)\n",
    "\n",
    "        # Train\n",
    "        history = self.model.fit_generator(traingen.flow(X_train, y_train, batch_size=128), epochs=self.nb_epochs,\n",
    "                                           steps_per_epoch=len(X_train)/128, validation_data=valgen.flow(X_val, y_val),\n",
    "                                           callbacks=[time_cb, lr_cb]).history\n",
    "        history[\"time\"] = time_cb.times\n",
    "\n",
    "        # Save history\n",
    "        file_name = f\"{self.framework}_n{self.n}.dat\"\n",
    "        file_path = os.path.join('data', file_name)\n",
    "        #with open(file_name, \"wb\") as fp:\n",
    "        with open(file_path, \"wb\") as fp:\n",
    "            pickle.dump(history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main(n, framework):\n",
    "    # layers = 6n+2\n",
    "    net = ResNet(n, framework, nb_epochs=1)\n",
    "\n",
    "    # CIFAR\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "    # train\n",
    "    net.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "391/390 [==============================] - 283s 725ms/step - loss: 1.9770 - acc: 0.4053 - val_loss: 2.3470 - val_acc: 0.3373 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "main(3, \"keras_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
